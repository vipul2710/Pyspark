{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c76e4bc-ed4c-448b-affa-329ef5f4066b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,ArrayType,MapType\n",
    "\n",
    "data = [\n",
    " (\"James\", \"A\", \"Smith\", 3000),\n",
    " (\"Michael\", \"B\", \"Rose\", 4000),\n",
    " (\"Robert\", \"C\", \"Williams\", 2500),\n",
    " (\"Maria\", \"D\", \"Jones\", 5000)\n",
    "]\n",
    "\n",
    "schema = StructType([StructField(\"first_name\", StringType(), True),\n",
    "                     StructField(\"middle_name\", StringType(), True),\n",
    "                     StructField(\"surname\", StringType(), True),\n",
    "                     StructField(\"salary\", IntegerType(), True)])\n",
    "\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dc5ebaf-6098-4fed-a7ac-97d75bac7bfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    " (\"James\", \"A\", \"Smith\", \"NY\", 3000),\n",
    " (\"Michael\", \"B\", \"Rose\", \"CA\", 4000),\n",
    " (\"Robert\", \"C\", \"Williams\", \"TX\", 2500),\n",
    " (\"Maria\", \"D\", \"Jones\", \"CA\", 5000),\n",
    " (\"Jen\", \"\", \"Brown\", \"NY\", 0)\n",
    "]\n",
    "\n",
    "cols = [\"first\", \"middle\", \"last\", \"state\", \"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data, cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5067b248-674e-4cbf-8a77-b69a762dbc3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.select(\"first\",\"last\",\"state\")\n",
    "df2.show()\n",
    "from pyspark.sql.functions import col\n",
    "df3 = df.filter(col(\"salary\")>3000)\n",
    "df3.show()\n",
    "\n",
    "df4 = df.filter((col(\"state\") == \"CA\") | (col(\"state\") == \"NY\"))\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8e881f7-7581-4992-a516-3751ec7993a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create a new column salary_k = salary / 1000\n",
    "df1 = df.withColumn(\"salary_k\",col(\"salary\")/1000).show(truncate=False)\n",
    "\n",
    "#Create a new column full_name = first + \" \" + last\n",
    "from pyspark.sql.functions import concat, lit, col\n",
    "\n",
    "df_1 =df.withColumn(\"full_name\", concat(col(\"first\"), lit(\" \"), col(\"last\")))\n",
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7355ef7e-ed0f-4427-85ec-204619dedc58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#sort by salary descending\n",
    "df.sort(col(\"salary\").desc()).show(truncate=False)\n",
    "#Group by state and find the average salary\n",
    "\n",
    "df_sorted = df.orderBy(col(\"salary\").desc())\n",
    "df_top_per_state = df_sorted.dropDuplicates([\"state\"])\n",
    "df_top_per_state.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efc355bb-6dd4-4716-990a-d5b582953669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"state\").avg(\"salary\").show(truncate=False)\n",
    "\n",
    "#total_employers\n",
    "df.groupBy(\"state\").count().show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d7e4f0a-d18d-482c-b147-108c0b570014",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "state_dim = [\n",
    "  (\"NY\", \"East Coast\"),\n",
    "  (\"CA\", \"West Coast\"),\n",
    "  (\"TX\", \"South Central\")\n",
    "]\n",
    "\n",
    "df_dim = spark.createDataFrame(state_dim, [\"state\", \"region\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04606e38-e3df-4a9b-b571-137dec62e467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_inner = df.join(df_dim, df.state == df_dim.state, \"inner\")\n",
    "df_inner.show(truncate=False)\n",
    "df_left = df.join(df_dim, df.state == df_dim.state, \"left\")\n",
    "df_left.show(truncate=False)\n",
    "df_leftan = df.join(df_dim, df.state == df_dim.state, \"leftanti\")\n",
    "df_leftan.show(truncate=False)\n",
    "print(\"Unmatched count:\", df_leftan.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef1ddca5-7bb0-4760-b2a0-b372863ff048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "\n",
    "orders_data = [\n",
    "    (\"O1\", \"C1\", \"2024-01-10\", 1200.0, \"COMPLETED\", '{\"payment_mode\":\"CARD\",\"device\":\"MOBILE\",\"promo_code\":\"NEW10\"}'),\n",
    "    (\"O2\", \"C1\", \"2024-01-15\", 800.0, \"COMPLETED\", '{\"payment_mode\":\"UPI\",\"device\":\"WEB\",\"promo_code\":null}'),\n",
    "    (\"O3\", \"C1\", \"2024-01-20\", 0.0, \"CANCELLED\", '{\"payment_mode\":\"CARD\",\"device\":\"MOBILE\",\"promo_code\":\"NEW10\"}'),\n",
    "\n",
    "    (\"O4\", \"C2\", \"2024-02-05\", 500.0, \"COMPLETED\", '{\"payment_mode\":\"COD\",\"device\":\"MOBILE\",\"promo_code\":null}'),\n",
    "    (\"O5\", \"C2\", \"2024-02-18\", -100.0, \"COMPLETED\", '{\"payment_mode\":\"UPI\",\"device\":\"WEB\",\"promo_code\":\"SAVE5\"}'),\n",
    "\n",
    "    (\"O6\", \"C3\", \"2024-03-01\", 2000.0, \"COMPLETED\", '{\"payment_mode\":\"CARD\",\"device\":\"WEB\",\"promo_code\":\"BIGSALE\"}'),\n",
    "\n",
    "    # Customer not present in customers table\n",
    "    (\"O7\", \"C4\", \"2024-03-10\", 1500.0, \"COMPLETED\", '{\"payment_mode\":\"CARD\",\"device\":\"MOBILE\",\"promo_code\":\"NEW10\"}')\n",
    "]\n",
    "\n",
    "orders_schema = StructType([\n",
    "    StructField(\"order_id\", StringType(), False),\n",
    "    StructField(\"customer_id\", StringType(), False),\n",
    "    StructField(\"order_date\", StringType(), True),\n",
    "    StructField(\"order_amount\", DoubleType(), True),\n",
    "    StructField(\"order_status\", StringType(), True),\n",
    "    StructField(\"order_metadata\", StringType(), True)\n",
    "])\n",
    "\n",
    "orders_df = spark.createDataFrame(orders_data, orders_schema)\n",
    "orders_df.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83846c9c-0a3a-4671-83f9-0e13d70a1dfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_data = [\n",
    "    (\"C1\", \"Alice Johnson\", \"2023-12-01\", \"USA\"),\n",
    "    (\"C2\", \"Bob Smith\", \"2023-11-15\", \"India\"),\n",
    "    (\"C3\", \"Charlie Brown\", \"2024-01-05\", \"UK\")\n",
    "]\n",
    "\n",
    "customers_schema = StructType([\n",
    "    StructField(\"customer_id\", StringType(), False),\n",
    "    StructField(\"customer_name\", StringType(), True),\n",
    "    StructField(\"signup_date\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True)\n",
    "])\n",
    "\n",
    "customers_df = spark.createDataFrame(customers_data, customers_schema)\n",
    "customers_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "965546fa-6981-4d55-94fe-c3153f9ab3eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Task1.2\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "orders_df_1 = orders_df.withColumn(\"order_date\",\n",
    "to_date(col(\"order_date\"),\"yyyy-MM-dd\").alias(\"order_date\"))\n",
    "\n",
    "\n",
    "\n",
    "orders_df_1.printSchema()\n",
    "\n",
    "\n",
    "customers_df_1 = customers_df.withColumn((\"signup_date\"),to_date(col(\"signup_date\"),\"yyyy-MM-dd\").alias(\"signup_date\"))\n",
    "customers_df_1.show()\n",
    "customers_df_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5797c7a6-7afb-4f6e-8839-557f88a0c2d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_df_2 = orders_df_1 \\\n",
    "    .withColumn(\"payment_mode\", json_tuple(col(\"order_metadata\"), \"payment_mode\")) \\\n",
    "    .withColumn(\"device\", json_tuple(col(\"order_metadata\"), \"device\")) \\\n",
    "    .withColumn(\"promo_code\", json_tuple(col(\"order_metadata\"), \"promo_code\"))\n",
    "\n",
    "orders_df_2.show(truncate=False)\n",
    "orders_df_2.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be32de60-a8e5-4b57-992f-687cc464db4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "order_df_up = orders_df_2.filter((col(\"order_status\") == \"COMPLETED\") & (col(\"order_amount\") > 0))\n",
    "order_df_up.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fe5f8d0-29ef-4251-8fca-b09daa74a70f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Ord_cus = order_df_up.join(customers_df_1, order_df_up.customer_id == customers_df_1.customer_id, \"left\")\n",
    "#order_df_up.join(customers_df_1, on=\"customer_id\", how=\"left\")\n",
    "Ord_cus.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83a324d7-762c-4fa9-acf8-93fb3004aade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, count, avg\n",
    "\n",
    "Ord_cus_clean = Ord_cus.drop(customers_df_1.customer_id)\n",
    "\n",
    "cust_metrics = (\n",
    "    Ord_cus_clean\n",
    "    .groupBy(\"customer_id\")\n",
    "    .agg(\n",
    "        sum(\"order_amount\").alias(\"total_order_amount\"),\n",
    "        count(\"order_id\").alias(\"total_orders\"),\n",
    "        avg(\"order_amount\").alias(\"average_order_value\")\n",
    "    )\n",
    ")\n",
    "\n",
    "cust_metrics.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cf402d9-50ae-4d67-a278-28008c732525",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "windowSpec  = Window.partitionBy(\"customer_id\").orderBy(col(\"order_date\").desc())\n",
    "\n",
    "Ord_cus_clean2 = Ord_cus_clean.withColumn(\"row_number\",row_number().over(windowSpec))\n",
    "\n",
    "Ord_cus_clean3 = Ord_cus_clean2.filter(\n",
    "    col(\"row_number\") == 1\n",
    ")\n",
    "display(Ord_cus_clean3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "900dc096-0514-4b17-abda-bfebf109101c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Ord_cus_flagged = Ord_cus_clean2.withColumn(\n",
    "    \"is_latest_order\",\n",
    "    when(col(\"row_number\") == 1, True).otherwise(False)\n",
    ")\n",
    "\n",
    "Ord_cus_flagged.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1af9c037-4d36-4403-bded-1bd9e4aa5294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#customers_df_1\n",
    "#cust_metrics\n",
    "\n",
    "final_cust = customers_df_1.join(cust_metrics , on=\"customer_id\",how=\"left\")\n",
    "final_cust = final_cust.drop(\"signup_date\")\n",
    "final_cust.show(truncate= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e8e4b73-2bec-41cd-bdf1-156821e1c4a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#display(Ord_cus_clean3)\n",
    "\n",
    "column_need = [\"customer_id\",\"order_date\",\"payment_mode\",\"device\"]\n",
    "order_last = Ord_cus_clean3.select(column_need)\n",
    "order_last.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c15997df-1bce-4d7c-b69d-99c8fcd9faa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df  = final_cust.join(order_last , on=\"customer_id\",how=\"left\")\n",
    "final_df = final_df.withColumnRenamed(\"order_date\",\"last_order\")\n",
    "final_df.show(truncate = False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "practice intensive pyspark",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
